project_name: "my-rag-application"
environment: "development"

logging:
  level: "INFO"

document_processing:
  chunk_size: 1000
  chunk_overlap: 200
  chunking:
    strategy: "recursive"  # Options: recursive, agentic, proposition
  # agentic_chunking:
  #   max_chunk_size: 1000
  #   similarity_threshold: 0.5
  # proposition_chunking:
  #   max_propositions_per_chunk: 5

embeddings:
  provider: "openai" # Options: openai, cohere, gemini, voyage
  openai:
    model: "text-embedding-3-small"
  # cohere:
  #   model: "embed-english-v3.0"
  # gemini:
  #   model: "models/text-embedding-004"
  # voyage:
  #   model: "voyage-large-2"

vectorstore:
  provider: "memory"
  # pinecone:
  #   index_name: "my-index"

llm:
  provider: "openai" # Options: openai, gemini, anthropic, cohere
  openai:
    model: "gpt-3.5-turbo"
    temperature: 0.7
  # gemini:
  #   model: "gemini-1.5-pro"
  # anthropic:
  #   model: "claude-3-5-sonnet-20240620"
  # cohere:
  #   model: "command-r-plus"

retrieval:
  strategy: "dense"  # Options: dense, graph_rag, raptor
  top_k: 5
  corrective_rag_enabled: false
  # graph_rag:
  #   max_entities_per_chunk: 10
  #   max_relationships_per_chunk: 15
  # raptor:
  #   num_levels: 3
  #   clustering_method: "kmeans"
  #   max_clusters_per_level: 10
  # corrective_rag:
  #   relevance_threshold: 0.7
  #   max_refinement_attempts: 2

generation:
  strategy: "standard"  # Options: standard, cove, attributed
# cove:
#   max_verification_questions: 3
# attributed_generation:
#   citation_style: "numeric"
